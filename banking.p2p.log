2021-05-03 20:17:56.362  INFO 14232 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 14232 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:17:56.365  INFO 14232 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:17:57.021  INFO 14232 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:17:57.041  INFO 14232 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:17:57.045  INFO 14232 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:17:57.048  INFO 14232 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:17:57.117  INFO 14232 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:17:57.135  INFO 14232 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:17:57.138  INFO 14232 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:17:57.573  INFO 14232 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:17:57.827  INFO 14232 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:17:57.933  INFO 14232 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:17:57.934  INFO 14232 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:17:57.934  INFO 14232 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:17:57.935  INFO 14232 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:17:58.109  INFO 14232 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:17:58.110  INFO 14232 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:17:58.231  INFO 14232 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:17:58.361  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:17:58.363  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:17:58.363  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062278360
2021-05-03 20:17:58.934  INFO 14232 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:17:58.970  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:17:58.970  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:17:58.970  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062278970
2021-05-03 20:17:58.980  INFO 14232 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-1, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:17:59.005  INFO 14232 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54.errors' has 1 subscriber(s).
2021-05-03 20:17:59.006  INFO 14232 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54.errors' has 0 subscriber(s).
2021-05-03 20:17:59.006  INFO 14232 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54.errors' has 1 subscriber(s).
2021-05-03 20:17:59.006  INFO 14232 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54.errors' has 2 subscriber(s).
2021-05-03 20:17:59.022  INFO 14232 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:17:59.029  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:17:59.029  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:17:59.029  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062279029
2021-05-03 20:17:59.031  INFO 14232 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Subscribed to topic(s): bankingQ
2021-05-03 20:17:59.032  INFO 14232 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:17:59.038  INFO 14232 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@60f21960
2021-05-03 20:17:59.050  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:17:59.085  INFO 14232 --- [main] Chat.ChatApplication                     : Started ChatApplication in 3.247 seconds (JVM running for 916.593)
2021-05-03 20:17:59.087 DEBUG 14232 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: ed@afeka.ac.il
2021-05-03 20:17:59.866  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:17:59.868  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] (Re-)joining group
2021-05-03 20:17:59.891  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:17:59.891  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] (Re-)joining group
2021-05-03 20:17:59.907  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Finished assignment for group at generation 1: {consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2-2d7171da-f71f-4606-b9e3-fadb1fa2470c=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:17:59.952  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Successfully joined group with generation 1
2021-05-03 20:17:59.953  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:17:59.955  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:17:59.964  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Found no committed offset for partition bankingQ-0
2021-05-03 20:17:59.971  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Found no committed offset for partition bankingQ-0
2021-05-03 20:17:59.985  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Resetting offset for partition bankingQ-0 to offset 0.
2021-05-03 20:18:00.001  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54: partitions assigned: [bankingQ-0]
2021-05-03 20:18:04.320 DEBUG 14232 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"ed@afeka.ac.il","contnet":"hello","timestamp":1620062284286}
2021-05-03 20:18:04.322  INFO 14232 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:18:04.331  INFO 14232 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:18:04.331  INFO 14232 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:18:04.337  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:18:04.338  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:18:04.338  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062284337
2021-05-03 20:18:04.364  INFO 14232 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:18:04.380  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:18:04.380  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:18:04.380  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062284380
2021-05-03 20:18:04.389  INFO 14232 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:18:04.391  INFO 14232 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:18:04.402  INFO 14232 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:18:04.415  INFO 14232 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:18:04.418  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:18:04.418  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:18:04.419  INFO 14232 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062284418
2021-05-03 20:18:04.426  INFO 14232 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:18:04.489 DEBUG 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"ed@afeka.ac.il","contnet":"hello","timestamp":1620062284286}
2021-05-03 20:19:05.581  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Revoke previously assigned partitions bankingQ-0
2021-05-03 20:19:05.583  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54: partitions revoked: [bankingQ-0]
2021-05-03 20:19:05.583  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Member consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2-2d7171da-f71f-4606-b9e3-fadb1fa2470c sending LeaveGroup request to coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2021-05-03 20:19:05.584  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54-2, groupId=anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54] Unsubscribed all topics or patterns and assigned partitions
2021-05-03 20:19:05.585  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2021-05-03 20:19:05.597  INFO 14232 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] essageListenerContainer$ListenerConsumer : anonymous.adb1fbce-25d5-4c0a-9341-f9adf4f59a54: Consumer stopped
2021-05-03 20:19:05.598  INFO 14232 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : stopped org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@60f21960
2021-05-03 20:19:05.599  INFO 14232 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:19:05.599  INFO 14232 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 0 subscriber(s).
2021-05-03 20:19:05.599  INFO 14232 --- [main] o.s.i.endpoint.EventDrivenConsumer       : stopped bean '_org.springframework.integration.errorLogger'
2021-05-03 20:19:05.600  INFO 14232 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2021-05-03 20:26:17.157  INFO 1084 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 1084 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:26:17.160  INFO 1084 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:26:17.957  INFO 1084 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:26:17.975  INFO 1084 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:26:17.979  INFO 1084 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:26:17.984  INFO 1084 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:26:18.047  INFO 1084 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:26:18.069  INFO 1084 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:26:18.070  INFO 1084 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:26:18.554  INFO 1084 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:26:18.873  INFO 1084 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:26:19.006  INFO 1084 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:26:19.007  INFO 1084 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:26:19.007  INFO 1084 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:26:19.008  INFO 1084 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:26:19.236  INFO 1084 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:26:19.237  INFO 1084 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:26:19.352  INFO 1084 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:26:19.503  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:19.505  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:19.505  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062779500
2021-05-03 20:26:19.911  INFO 1084 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8a6be6b7-5347-4499-b035-1829335bfc73
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:26:19.951  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:19.952  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:19.952  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062779951
2021-05-03 20:26:19.960  INFO 1084 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-1, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:26:19.985  INFO 1084 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.8a6be6b7-5347-4499-b035-1829335bfc73.errors' has 1 subscriber(s).
2021-05-03 20:26:19.986  INFO 1084 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.8a6be6b7-5347-4499-b035-1829335bfc73.errors' has 0 subscriber(s).
2021-05-03 20:26:19.986  INFO 1084 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.8a6be6b7-5347-4499-b035-1829335bfc73.errors' has 1 subscriber(s).
2021-05-03 20:26:19.986  INFO 1084 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.8a6be6b7-5347-4499-b035-1829335bfc73.errors' has 2 subscriber(s).
2021-05-03 20:26:20.002  INFO 1084 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8a6be6b7-5347-4499-b035-1829335bfc73
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:26:20.010  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:20.010  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:20.010  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062780010
2021-05-03 20:26:20.012  INFO 1084 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Subscribed to topic(s): bankingQ
2021-05-03 20:26:20.015  INFO 1084 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:26:20.021  INFO 1084 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@183ade54
2021-05-03 20:26:20.033  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:26:20.034  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:26:20.037  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] (Re-)joining group
2021-05-03 20:26:20.053  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:26:20.054  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] (Re-)joining group
2021-05-03 20:26:20.057  INFO 1084 --- [main] Chat.ChatApplication                     : Started ChatApplication in 3.544 seconds (JVM running for 12.431)
2021-05-03 20:26:20.060 DEBUG 1084 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: bar@gmail.com
2021-05-03 20:26:20.062  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Finished assignment for group at generation 1: {consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2-a7b5dfef-d396-46a3-a8c3-84c332bce23f=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:26:20.067  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Successfully joined group with generation 1
2021-05-03 20:26:20.068  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:26:20.072  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:26:20.076  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Found no committed offset for partition bankingQ-0
2021-05-03 20:26:20.084  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Found no committed offset for partition bankingQ-0
2021-05-03 20:26:20.096  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.8a6be6b7-5347-4499-b035-1829335bfc73-2, groupId=anonymous.8a6be6b7-5347-4499-b035-1829335bfc73] Resetting offset for partition bankingQ-0 to offset 1.
2021-05-03 20:26:20.103  INFO 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.8a6be6b7-5347-4499-b035-1829335bfc73: partitions assigned: [bankingQ-0]
2021-05-03 20:26:27.133 DEBUG 1084 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"bar@gmail.com","contnet":"hi bar","timestamp":1620062787102}
2021-05-03 20:26:27.135  INFO 1084 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:26:27.151  INFO 1084 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:26:27.151  INFO 1084 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:26:27.159  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:27.159  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:27.159  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062787159
2021-05-03 20:26:27.185  INFO 1084 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:26:27.207  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:27.208  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:27.208  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062787207
2021-05-03 20:26:27.217  INFO 1084 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:26:27.219  INFO 1084 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:26:27.232  INFO 1084 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:26:27.256  INFO 1084 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:26:27.261  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:26:27.261  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:26:27.261  INFO 1084 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062787261
2021-05-03 20:26:27.267  INFO 1084 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:26:27.324 DEBUG 1084 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"bar@gmail.com","contnet":"hi bar","timestamp":1620062787102}
2021-05-03 20:28:58.943  INFO 19732 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 19732 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:28:58.945  INFO 19732 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:28:59.777  INFO 19732 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:28:59.794  INFO 19732 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:28:59.800  INFO 19732 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:28:59.804  INFO 19732 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:28:59.863  INFO 19732 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:28:59.881  INFO 19732 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:28:59.883  INFO 19732 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:29:00.431  INFO 19732 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:29:00.815  INFO 19732 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:29:01.018  INFO 19732 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:29:01.019  INFO 19732 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:29:01.021  INFO 19732 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:29:01.024  INFO 19732 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:29:01.638  INFO 19732 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:29:01.639  INFO 19732 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:29:01.886  INFO 19732 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:29:02.068  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:02.070  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:02.070  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062942066
2021-05-03 20:29:02.453  INFO 19732 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:29:02.487  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:02.488  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:02.488  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062942487
2021-05-03 20:29:02.499  INFO 19732 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-1, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:29:02.533  INFO 19732 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c.errors' has 1 subscriber(s).
2021-05-03 20:29:02.536  INFO 19732 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c.errors' has 0 subscriber(s).
2021-05-03 20:29:02.536  INFO 19732 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c.errors' has 1 subscriber(s).
2021-05-03 20:29:02.536  INFO 19732 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c.errors' has 2 subscriber(s).
2021-05-03 20:29:02.559  INFO 19732 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:29:02.569  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:02.569  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:02.569  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062942568
2021-05-03 20:29:02.571  INFO 19732 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Subscribed to topic(s): bankingQ
2021-05-03 20:29:02.574  INFO 19732 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:29:02.581  INFO 19732 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@5d512ddb
2021-05-03 20:29:02.593  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:29:02.596  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:29:02.598  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] (Re-)joining group
2021-05-03 20:29:02.610  INFO 19732 --- [main] Chat.ChatApplication                     : Started ChatApplication in 4.318 seconds (JVM running for 85.552)
2021-05-03 20:29:02.612 DEBUG 19732 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: bar.;e
2021-05-03 20:29:02.615  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:29:02.616  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] (Re-)joining group
2021-05-03 20:29:02.622  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Finished assignment for group at generation 1: {consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2-ae6fe01b-2d9c-4877-b280-01d551e74612=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:29:02.629  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Successfully joined group with generation 1
2021-05-03 20:29:02.629  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:29:02.633  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:29:02.638  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Found no committed offset for partition bankingQ-0
2021-05-03 20:29:02.644  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Found no committed offset for partition bankingQ-0
2021-05-03 20:29:02.657  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c-2, groupId=anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c] Resetting offset for partition bankingQ-0 to offset 2.
2021-05-03 20:29:02.668  INFO 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.06c0a8ad-6316-49ec-bce7-9d2bd9361c5c: partitions assigned: [bankingQ-0]
2021-05-03 20:29:06.518 DEBUG 19732 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"bar.;e","contnet":"hi 1","timestamp":1620062946484}
2021-05-03 20:29:06.519  INFO 19732 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:29:06.541  INFO 19732 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:29:06.541  INFO 19732 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:29:06.546  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:06.546  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:06.546  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062946546
2021-05-03 20:29:06.575  INFO 19732 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:29:06.595  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:06.596  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:06.596  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062946595
2021-05-03 20:29:06.601  INFO 19732 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:29:06.603  INFO 19732 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:29:06.619  INFO 19732 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:29:06.643  INFO 19732 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:29:06.650  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:29:06.651  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:29:06.651  INFO 19732 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620062946650
2021-05-03 20:29:06.655  INFO 19732 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:29:06.714 DEBUG 19732 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"bar.;e","contnet":"hi 1","timestamp":1620062946484}
2021-05-03 20:55:02.303  INFO 14856 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 14856 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:55:02.306  INFO 14856 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:55:02.965  INFO 14856 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:55:02.979  INFO 14856 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:55:02.983  INFO 14856 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:55:02.986  INFO 14856 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:55:03.049  INFO 14856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:03.060  INFO 14856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:03.062  INFO 14856 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:03.535  INFO 14856 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:55:03.784  INFO 14856 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:55:03.892  INFO 14856 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:55:03.893  INFO 14856 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:55:03.893  INFO 14856 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:55:03.894  INFO 14856 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:55:04.094  INFO 14856 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:55:04.094  INFO 14856 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:04.199  INFO 14856 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:04.311  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:04.312  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:04.313  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064504311
2021-05-03 20:55:04.616  INFO 14856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.6b6a642a-db84-4b09-b384-643391da599c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:04.654  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:04.655  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:04.655  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064504654
2021-05-03 20:55:04.667  INFO 14856 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-1, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:04.704  INFO 14856 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.6b6a642a-db84-4b09-b384-643391da599c.errors' has 1 subscriber(s).
2021-05-03 20:55:04.705  INFO 14856 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.6b6a642a-db84-4b09-b384-643391da599c.errors' has 0 subscriber(s).
2021-05-03 20:55:04.706  INFO 14856 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.6b6a642a-db84-4b09-b384-643391da599c.errors' has 1 subscriber(s).
2021-05-03 20:55:04.706  INFO 14856 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.6b6a642a-db84-4b09-b384-643391da599c.errors' has 2 subscriber(s).
2021-05-03 20:55:04.732  INFO 14856 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.6b6a642a-db84-4b09-b384-643391da599c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:04.739  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:04.739  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:04.739  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064504739
2021-05-03 20:55:04.740  INFO 14856 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Subscribed to topic(s): bankingQ
2021-05-03 20:55:04.742  INFO 14856 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:55:04.748  INFO 14856 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@707ca986
2021-05-03 20:55:04.757  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:04.759  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:55:04.761  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] (Re-)joining group
2021-05-03 20:55:04.776  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:55:04.777  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] (Re-)joining group
2021-05-03 20:55:04.779  INFO 14856 --- [main] Chat.ChatApplication                     : Started ChatApplication in 3.012 seconds (JVM running for 7.689)
2021-05-03 20:55:04.780 DEBUG 14856 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: bar
2021-05-03 20:55:04.783  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Finished assignment for group at generation 1: {consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2-a575856f-30ce-46dc-9d49-0c7332cf29aa=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:55:04.787  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Successfully joined group with generation 1
2021-05-03 20:55:04.788  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:55:04.791  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:55:04.795  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:04.803  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:04.812  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.6b6a642a-db84-4b09-b384-643391da599c-2, groupId=anonymous.6b6a642a-db84-4b09-b384-643391da599c] Resetting offset for partition bankingQ-0 to offset 3.
2021-05-03 20:55:04.819  INFO 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.6b6a642a-db84-4b09-b384-643391da599c: partitions assigned: [bankingQ-0]
2021-05-03 20:55:10.618 DEBUG 14856 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"bar","contnet":"hi from bar","timestamp":1620064510585}
2021-05-03 20:55:10.621  INFO 14856 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:10.641  INFO 14856 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:55:10.642  INFO 14856 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:10.646  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:10.646  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:10.646  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064510646
2021-05-03 20:55:10.668  INFO 14856 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:10.690  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:10.691  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:10.691  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064510690
2021-05-03 20:55:10.695  INFO 14856 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:10.697  INFO 14856 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:55:10.709  INFO 14856 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:55:10.730  INFO 14856 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:10.735  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:10.736  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:10.736  INFO 14856 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064510735
2021-05-03 20:55:10.740  INFO 14856 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:10.798 DEBUG 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"bar","contnet":"hi from bar","timestamp":1620064510585}
2021-05-03 20:55:19.876  INFO 15772 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 15772 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:55:19.878  INFO 15772 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:55:20.480  INFO 15772 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:55:20.493  INFO 15772 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:55:20.497  INFO 15772 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:55:20.500  INFO 15772 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:55:20.544  INFO 15772 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:20.555  INFO 15772 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:20.556  INFO 15772 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:20.929  INFO 15772 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:55:21.188  INFO 15772 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:55:21.296  INFO 15772 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:55:21.297  INFO 15772 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:55:21.297  INFO 15772 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:55:21.298  INFO 15772 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:55:21.491  INFO 15772 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:55:21.491  INFO 15772 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:21.615  INFO 15772 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:21.737  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:21.738  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:21.738  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064521735
2021-05-03 20:55:22.090  INFO 15772 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:22.137  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:22.137  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:22.137  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064522137
2021-05-03 20:55:22.149  INFO 15772 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-1, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:22.189  INFO 15772 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373.errors' has 1 subscriber(s).
2021-05-03 20:55:22.191  INFO 15772 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373.errors' has 0 subscriber(s).
2021-05-03 20:55:22.191  INFO 15772 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373.errors' has 1 subscriber(s).
2021-05-03 20:55:22.191  INFO 15772 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373.errors' has 2 subscriber(s).
2021-05-03 20:55:22.209  INFO 15772 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:22.216  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:22.217  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:22.217  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064522216
2021-05-03 20:55:22.219  INFO 15772 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Subscribed to topic(s): bankingQ
2021-05-03 20:55:22.222  INFO 15772 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:55:22.229  INFO 15772 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@707ca986
2021-05-03 20:55:22.239  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:22.240  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:55:22.242  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] (Re-)joining group
2021-05-03 20:55:22.255  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:55:22.256  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] (Re-)joining group
2021-05-03 20:55:22.260  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Finished assignment for group at generation 1: {consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2-3ce49719-c777-44fe-815a-3e3b5071a1ab=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:55:22.261  INFO 15772 --- [main] Chat.ChatApplication                     : Started ChatApplication in 2.912 seconds (JVM running for 91.936)
2021-05-03 20:55:22.262 DEBUG 15772 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: hen
2021-05-03 20:55:22.265  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Successfully joined group with generation 1
2021-05-03 20:55:22.266  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:55:22.269  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:55:22.273  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:22.279  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:22.288  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373-2, groupId=anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373] Resetting offset for partition bankingQ-0 to offset 4.
2021-05-03 20:55:22.294  INFO 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.1c352e08-22cd-4418-99ae-7a9f9924a373: partitions assigned: [bankingQ-0]
2021-05-03 20:55:26.899 DEBUG 15772 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"hen","contnet":"hello from hen","timestamp":1620064526862}
2021-05-03 20:55:26.901  INFO 15772 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:26.923  INFO 15772 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:55:26.923  INFO 15772 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:26.927  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:26.927  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:26.927  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064526927
2021-05-03 20:55:26.952  INFO 15772 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:26.973  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:26.973  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:26.973  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064526973
2021-05-03 20:55:26.980  INFO 15772 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:26.982  INFO 15772 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:55:26.997  INFO 15772 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:55:27.021  INFO 15772 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:27.028  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:27.028  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:27.028  INFO 15772 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064527028
2021-05-03 20:55:27.037  INFO 15772 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:27.076 DEBUG 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"hen","contnet":"hello from hen","timestamp":1620064526862}
2021-05-03 20:55:27.125 DEBUG 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"hen","contnet":"hello from hen","timestamp":1620064526862}
2021-05-03 20:55:46.060  INFO 7940 --- [main] Chat.ChatApplication                     : Starting ChatApplication using Java 14.0.1 on DESKTOP-0D7HRTH with PID 7940 (C:\Users\edens\IdeaProjects\Bank\out\production\Bank started by edens in C:\Users\edens\IdeaProjects\Bank)
2021-05-03 20:55:46.062  INFO 7940 --- [main] Chat.ChatApplication                     : No active profile set, falling back to default profiles: default
2021-05-03 20:55:46.712  INFO 7940 --- [main] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-03 20:55:46.726  INFO 7940 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-03 20:55:46.730  INFO 7940 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-03 20:55:46.733  INFO 7940 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-03 20:55:46.782  INFO 7940 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:46.797  INFO 7940 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:46.798  INFO 7940 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-03 20:55:47.225  INFO 7940 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-03 20:55:47.492  INFO 7940 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-03 20:55:47.608  INFO 7940 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-03 20:55:47.609  INFO 7940 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-03 20:55:47.609  INFO 7940 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-03 20:55:47.611  INFO 7940 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-03 20:55:47.798  INFO 7940 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-03 20:55:47.799  INFO 7940 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:47.900  INFO 7940 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:48.027  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:48.029  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:48.029  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064548025
2021-05-03 20:55:48.325  INFO 7940 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.558b3961-5269-4c72-85b6-141ebe04fb02
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:48.356  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:48.356  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:48.356  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064548356
2021-05-03 20:55:48.365  INFO 7940 --- [main] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-1, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:48.400  INFO 7940 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.558b3961-5269-4c72-85b6-141ebe04fb02.errors' has 1 subscriber(s).
2021-05-03 20:55:48.402  INFO 7940 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.558b3961-5269-4c72-85b6-141ebe04fb02.errors' has 0 subscriber(s).
2021-05-03 20:55:48.402  INFO 7940 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.558b3961-5269-4c72-85b6-141ebe04fb02.errors' has 1 subscriber(s).
2021-05-03 20:55:48.402  INFO 7940 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'bankingQ.anonymous.558b3961-5269-4c72-85b6-141ebe04fb02.errors' has 2 subscriber(s).
2021-05-03 20:55:48.419  INFO 7940 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.558b3961-5269-4c72-85b6-141ebe04fb02
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-03 20:55:48.425  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:48.425  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:48.425  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064548425
2021-05-03 20:55:48.426  INFO 7940 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Subscribed to topic(s): bankingQ
2021-05-03 20:55:48.428  INFO 7940 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-03 20:55:48.432  INFO 7940 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@6435fa1c
2021-05-03 20:55:48.446  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:48.449  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Discovered group coordinator DESKTOP-0D7HRTH.lan:9092 (id: 2147483647 rack: null)
2021-05-03 20:55:48.452  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] (Re-)joining group
2021-05-03 20:55:48.467  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-03 20:55:48.467  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] (Re-)joining group
2021-05-03 20:55:48.470  INFO 7940 --- [main] Chat.ChatApplication                     : Started ChatApplication in 2.926 seconds (JVM running for 122.788)
2021-05-03 20:55:48.473 DEBUG 7940 --- [main] p2p.banking.BankingInterchange           : initialized bank partner: tareq
2021-05-03 20:55:48.473  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Finished assignment for group at generation 1: {consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2-8ccb96bc-9f6e-45cb-b2f0-98747848c5ed=Assignment(partitions=[bankingQ-0])}
2021-05-03 20:55:48.477  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Successfully joined group with generation 1
2021-05-03 20:55:48.478  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Notifying assignor about the new Assignment(partitions=[bankingQ-0])
2021-05-03 20:55:48.484  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Adding newly assigned partitions: bankingQ-0
2021-05-03 20:55:48.487  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:48.492  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Found no committed offset for partition bankingQ-0
2021-05-03 20:55:48.502  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-anonymous.558b3961-5269-4c72-85b6-141ebe04fb02-2, groupId=anonymous.558b3961-5269-4c72-85b6-141ebe04fb02] Resetting offset for partition bankingQ-0 to offset 5.
2021-05-03 20:55:48.507  INFO 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$2  : anonymous.558b3961-5269-4c72-85b6-141ebe04fb02: partitions assigned: [bankingQ-0]
2021-05-03 20:55:53.166 DEBUG 7940 --- [main] p2p.core.MessageHandler                  : sending: {"sender":"tareq","contnet":"hi from tareq","timestamp":1620064553134}
2021-05-03 20:55:53.167  INFO 7940 --- [main] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-03 20:55:53.184  INFO 7940 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-03 20:55:53.185  INFO 7940 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-03 20:55:53.188  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:53.188  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:53.188  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064553188
2021-05-03 20:55:53.211  INFO 7940 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:53.227  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:53.227  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:53.228  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064553227
2021-05-03 20:55:53.231  INFO 7940 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:53.233  INFO 7940 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2021-05-03 20:55:53.242  INFO 7940 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'unknown.channel.name' has 1 subscriber(s).
2021-05-03 20:55:53.259  INFO 7940 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-03 20:55:53.261  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-03 20:55:53.262  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-03 20:55:53.262  INFO 7940 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1620064553261
2021-05-03 20:55:53.265  INFO 7940 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: 0ISoXIaSTq-eBNh7hCB7Rg
2021-05-03 20:55:53.289 DEBUG 14856 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"tareq","contnet":"hi from tareq","timestamp":1620064553134}
2021-05-03 20:55:53.292 DEBUG 15772 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"tareq","contnet":"hi from tareq","timestamp":1620064553134}
2021-05-03 20:55:53.322 DEBUG 7940 --- [KafkaConsumerDestination{consumerDestinationName='bankingQ', partitions=1, dlqName='null'}.container-0-C-1] p2p.core.MessageHandler                  : received: {"sender":"tareq","contnet":"hi from tareq","timestamp":1620064553134}
2021-05-21 14:28:19.605  INFO 17112 --- [JavaFX Application Thread] o.s.boot.SpringApplication               : Starting application using Java 14.0.1 on DESKTOP-0D7HRTH with PID 17112 (started by edens in C:\Users\edens\IdeaProjects\DigitalBank)
2021-05-21 14:28:19.607  INFO 17112 --- [JavaFX Application Thread] o.s.boot.SpringApplication               : No active profile set, falling back to default profiles: default
2021-05-21 14:28:20.342  INFO 17112 --- [JavaFX Application Thread] o.s.c.a.ConfigurationClassEnhancer       : @Bean method FunctionConfiguration.po is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2021-05-21 14:28:20.365  INFO 17112 --- [JavaFX Application Thread] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2021-05-21 14:28:20.371  INFO 17112 --- [JavaFX Application Thread] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2021-05-21 14:28:20.376  INFO 17112 --- [JavaFX Application Thread] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2021-05-21 14:28:20.445  INFO 17112 --- [JavaFX Application Thread] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-21 14:28:20.465  INFO 17112 --- [JavaFX Application Thread] trationDelegate$BeanPostProcessorChecker : Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-21 14:28:20.467  INFO 17112 --- [JavaFX Application Thread] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2021-05-21 14:28:20.945  INFO 17112 --- [JavaFX Application Thread] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-21 14:28:21.228  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'bankinginterchange.handleMessage-in-0' has 1 subscriber(s).
2021-05-21 14:28:21.337  INFO 17112 --- [JavaFX Application Thread] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2021-05-21 14:28:21.337  INFO 17112 --- [JavaFX Application Thread] o.s.i.channel.PublishSubscribeChannel    : Channel 'bankinginterchange.errorChannel' has 1 subscriber(s).
2021-05-21 14:28:21.337  INFO 17112 --- [JavaFX Application Thread] o.s.i.endpoint.EventDrivenConsumer       : started bean '_org.springframework.integration.errorLogger'
2021-05-21 14:28:21.338  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.binder.DefaultBinderFactory      : Creating binder: kafka
2021-05-21 14:28:21.510  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.binder.DefaultBinderFactory      : Caching the binder: kafka
2021-05-21 14:28:21.511  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-21 14:28:21.601  INFO 17112 --- [JavaFX Application Thread] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-21 14:28:21.742  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-21 14:28:21.744  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-21 14:28:21.745  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621596501740
2021-05-21 14:28:23.812  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:25.946  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:28.083  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:30.402  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:32.934  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:35.879  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:39.028  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:41.987  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:45.149  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:48.080  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:51.127  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:51.757  INFO 17112 --- [kafka-admin-client-thread | adminclient-1] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-1] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1621596531748, tries=1, nextAllowedTryMs=1621596531849) timed out at 1621596531749 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment.

2021-05-21 14:28:54.210  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:28:57.460  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:00.707  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:03.847  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:06.804  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:09.858  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:12.795  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:16.040  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:19.287  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:21.750  INFO 17112 --- [kafka-admin-client-thread | adminclient-1] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-1] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1621596561749, tries=1, nextAllowedTryMs=1621596561850) timed out at 1621596561750 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.

2021-05-21 14:29:22.348  WARN 17112 --- [kafka-admin-client-thread | adminclient-1] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-1] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:22.351  INFO 17112 --- [kafka-admin-client-thread | adminclient-1] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-1] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1621596591750, tries=1, nextAllowedTryMs=-9223372036854775709) timed out at 9223372036854775807 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited.

2021-05-21 14:29:22.367 ERROR 17112 --- [JavaFX Application Thread] o.s.cloud.stream.binding.BindingService  : Failed to create consumer binding; retrying in 30 seconds

org.springframework.cloud.stream.provisioning.ProvisioningException: Provisioning exception encountered for bankingQ; nested exception is java.util.concurrent.TimeoutException
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.createTopic(KafkaTopicProvisioner.java:346) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.doProvisionConsumerDestination(KafkaTopicProvisioner.java:231) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.provisionConsumerDestination(KafkaTopicProvisioner.java:197) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.provisionConsumerDestination(KafkaTopicProvisioner.java:86) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.AbstractMessageChannelBinder.doBindConsumer(AbstractMessageChannelBinder.java:403) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.AbstractMessageChannelBinder.doBindConsumer(AbstractMessageChannelBinder.java:91) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.AbstractBinder.bindConsumer(AbstractBinder.java:143) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binding.BindingService.doBindConsumer(BindingService.java:176) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binding.BindingService.bindConsumer(BindingService.java:133) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binding.AbstractBindableProxyFactory.createAndBindInputs(AbstractBindableProxyFactory.java:112) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binding.InputBindingLifecycle.doStartWithBindable(InputBindingLifecycle.java:58) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at java.base/java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:647) ~[na:na]
	at org.springframework.cloud.stream.binding.AbstractBindingLifecycle.start(AbstractBindingLifecycle.java:57) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binding.InputBindingLifecycle.start(InputBindingLifecycle.java:34) ~[spring-cloud-stream-3.1.2.jar:3.1.2]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.5.jar:5.3.5]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:935) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:586) ~[spring-context-5.3.5.jar:5.3.5]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:769) ~[spring-boot-2.4.4.jar:2.4.4]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:761) ~[spring-boot-2.4.4.jar:2.4.4]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.4.jar:2.4.4]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.4.jar:2.4.4]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1313) ~[spring-boot-2.4.4.jar:2.4.4]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1302) ~[spring-boot-2.4.4.jar:2.4.4]
	at p2p.core.P2pManagerImplementation.startP2P(P2pManagerImplementation.java:47) ~[p2p-bank-3.0.0-v1.8.jar:na]
	at p2p.core.P2pManager.getInstance(P2pManager.java:7) ~[p2p-bank-3.0.0-v1.8.jar:na]
	at p2p.banking.BankingInterchange.<init>(BankingInterchange.java:18) ~[p2p-bank-3.0.0-v1.8.jar:na]
	at Transaction.TransactionControl.<init>(TransactionControl.java:15) ~[Bank/:na]
	at user_interface.MenuScreen.transferMoneyFromAccount(MenuScreen.java:336) ~[Bank/:na]
	at user_interface.MenuScreen.access$1000(MenuScreen.java:30) ~[Bank/:na]
	at user_interface.MenuScreen$4.handle(MenuScreen.java:276) ~[Bank/:na]
	at user_interface.MenuScreen$4.handle(MenuScreen.java:271) ~[Bank/:na]
	at javafx.base/com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:86) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:49) ~[javafx.base.jar:na]
	at javafx.base/javafx.event.Event.fireEvent(Event.java:198) ~[javafx.base.jar:na]
	at javafx.graphics/javafx.scene.Node.fireEvent(Node.java:8879) ~[javafx.graphics.jar:na]
	at javafx.controls/javafx.scene.control.Button.fire(Button.java:200) ~[javafx.controls.jar:na]
	at javafx.controls/com.sun.javafx.scene.control.behavior.ButtonBehavior.mouseReleased(ButtonBehavior.java:206) ~[javafx.controls.jar:na]
	at javafx.controls/com.sun.javafx.scene.control.inputmap.InputMap.handle(InputMap.java:274) ~[javafx.controls.jar:na]
	at javafx.base/com.sun.javafx.event.CompositeEventHandler$NormalEventHandlerRecord.handleBubblingEvent(CompositeEventHandler.java:218) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.CompositeEventHandler.dispatchBubblingEvent(CompositeEventHandler.java:80) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:238) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventHandlerManager.dispatchBubblingEvent(EventHandlerManager.java:191) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.CompositeEventDispatcher.dispatchBubblingEvent(CompositeEventDispatcher.java:59) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:58) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.BasicEventDispatcher.dispatchEvent(BasicEventDispatcher.java:56) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventDispatchChainImpl.dispatchEvent(EventDispatchChainImpl.java:114) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventUtil.fireEventImpl(EventUtil.java:74) ~[javafx.base.jar:na]
	at javafx.base/com.sun.javafx.event.EventUtil.fireEvent(EventUtil.java:54) ~[javafx.base.jar:na]
	at javafx.base/javafx.event.Event.fireEvent(Event.java:198) ~[javafx.base.jar:na]
	at javafx.graphics/javafx.scene.Scene$MouseHandler.process(Scene.java:3851) ~[javafx.graphics.jar:na]
	at javafx.graphics/javafx.scene.Scene$MouseHandler.access$1200(Scene.java:3579) ~[javafx.graphics.jar:na]
	at javafx.graphics/javafx.scene.Scene.processMouseEvent(Scene.java:1849) ~[javafx.graphics.jar:na]
	at javafx.graphics/javafx.scene.Scene$ScenePeerListener.mouseEvent(Scene.java:2588) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:397) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.javafx.tk.quantum.GlassViewEventHandler$MouseEventNotification.run(GlassViewEventHandler.java:295) ~[javafx.graphics.jar:na]
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:391) ~[na:na]
	at javafx.graphics/com.sun.javafx.tk.quantum.GlassViewEventHandler.lambda$handleMouseEvent$2(GlassViewEventHandler.java:434) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.javafx.tk.quantum.QuantumToolkit.runWithoutRenderLock(QuantumToolkit.java:390) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.javafx.tk.quantum.GlassViewEventHandler.handleMouseEvent(GlassViewEventHandler.java:433) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.glass.ui.View.handleMouseEvent(View.java:556) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.glass.ui.View.notifyMouse(View.java:942) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.glass.ui.win.WinApplication._runLoop(Native Method) ~[javafx.graphics.jar:na]
	at javafx.graphics/com.sun.glass.ui.win.WinApplication.lambda$runLoop$3(WinApplication.java:174) ~[javafx.graphics.jar:na]
	at java.base/java.lang.Thread.run(Thread.java:832) ~[na:na]
Caused by: java.util.concurrent.TimeoutException: null
	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:108) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:272) ~[kafka-clients-2.6.0.jar:na]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.createTopicAndPartitions(KafkaTopicProvisioner.java:382) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.createTopicIfNecessary(KafkaTopicProvisioner.java:356) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	at org.springframework.cloud.stream.binder.kafka.provisioning.KafkaTopicProvisioner.createTopic(KafkaTopicProvisioner.java:333) ~[spring-cloud-stream-binder-kafka-core-3.1.2.jar:3.1.2]
	... 85 common frames omitted

2021-05-21 14:29:22.391  INFO 17112 --- [JavaFX Application Thread] o.s.boot.SpringApplication               : Started application in 63.519 seconds (JVM running for 213.132)
2021-05-21 14:29:22.394 DEBUG 17112 --- [JavaFX Application Thread] p2p.banking.BankingInterchange           : initialized bank partner: afeka02
2021-05-21 14:29:22.468 DEBUG 17112 --- [JavaFX Application Thread] p2p.core.MessageHandler                  : sending: {"source":{"accountNumber":"12345678","bankId":"afeka02","branch":"online","customerName":"client2"},"destination":{"accountNumber":"11122334","bankId":"afeka02","branch":"online","customerName":"client2"},"comment":"","timestamp":1621596498640,"amount":555.0}
2021-05-21 14:29:22.472  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.binder.DefaultBinderFactory      : Retrieving cached binder: kafka
2021-05-21 14:29:22.508  INFO 17112 --- [JavaFX Application Thread] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: bankingQ
2021-05-21 14:29:22.509  INFO 17112 --- [JavaFX Application Thread] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-21 14:29:22.520  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-21 14:29:22.521  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-21 14:29:22.521  INFO 17112 --- [JavaFX Application Thread] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621596562520
2021-05-21 14:29:24.571  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:26.721  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:28.865  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:31.216  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:33.655  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:36.576  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:39.601  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:42.855  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:45.893  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:48.943  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:52.186  WARN 17112 --- [kafka-admin-client-thread | adminclient-2] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-2] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
2021-05-21 14:29:52.378  INFO 17112 --- [task-scheduler-1] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-21 14:29:52.388  INFO 17112 --- [task-scheduler-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-21 14:29:52.389  INFO 17112 --- [task-scheduler-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-21 14:29:52.390  INFO 17112 --- [task-scheduler-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621596592388
2021-05-21 14:29:52.524  INFO 17112 --- [kafka-admin-client-thread | adminclient-2] o.a.k.c.a.i.AdminMetadataManager         : [AdminClient clientId=adminclient-2] Metadata update failed

org.apache.kafka.common.errors.TimeoutException: Call(callName=fetchMetadata, deadlineMs=1621596592523, tries=1, nextAllowedTryMs=1621596592624) timed out at 1621596592524 after 1 attempt(s)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment.

2021-05-21 14:29:54.418  WARN 17112 --- [kafka-admin-client-thread | adminclient-3] org.apache.kafka.clients.NetworkClient   : [AdminClient clientId=adminclient-3] Connection to node -1 (/127.0.0.1:9092) could not be established. Broker may not be available.
